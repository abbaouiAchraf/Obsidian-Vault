# Introduction
## Section 05 : Evaluation methodes
**Leave one out CV (LOO-CV)** is similar to K-fold, but in this case each one sample data point is held out as a validation set, and the rest of data set is the training set. Comparing LOO-CV and K-fold, K-fold is faster and requires less computation, but in terms of accuracy, LOO-CV often has a high variance as an estimator.
Means that if we have 10 000 row we ll have 10 000 accuracy value.

## IBM Watson services : 
note : Knowledge studio - > NLU as exemple.

WATSON is an service that provides APIs and SaaS
Watson ML Library in Python
**TIME SERIES FORCASTING !**

## NLP Evaluation
### Confusion matrix
![[Pasted image 20230315103203.png]]
### Accuracy
This does suck when we r dealing with unbalanced datasets
![[Pasted image 20230315103959.png]]
### Recall

![[Pasted image 20230315104018.png]]
### Precision
Chno dakxi li detecta useful or positive mn dakxi li detecta
![[Pasted image 20230315104037.png]]
### F1-Score
![[Pasted image 20230315104059.png]]




# API_KEY : 
**API_KEY** : Wh5zqUmWxT0dtg0bVcSB6pnWYrgzsWtAi_R_ebj-CEPe
![[Pasted image 20230315133939.png]]

Test Sync
# More Content
